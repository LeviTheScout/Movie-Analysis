{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeWnwvFy44XU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Short Films/Shortfilm Data/Shortfilms HandTagged/Shortfilms - InteriorCafeNight.csv') # this is just a example change the file name and location as needed\n"
      ],
      "metadata": {
        "id": "GDSt3XWA9i7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BGM Analysis"
      ],
      "metadata": {
        "id": "WGu911u3-cO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/purnima99/EmotionDetection.git\n"
      ],
      "metadata": {
        "id": "9uE76AYn9rms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EmotionDetection/Emotion-Detection-from-Audio\n"
      ],
      "metadata": {
        "id": "zjqRO_d7-j54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install librosa\n"
      ],
      "metadata": {
        "id": "Q2LeCB_Y-mQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "XhwAWPWc-pFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_path = '/content/EmotionDetection/Emotion-Detection-from-Audio/model/Emotion_Voice_Detection_Model.h5'\n",
        "model = load_model(model_path)\n"
      ],
      "metadata": {
        "id": "FPngKFy9-rpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def duration_to_seconds(duration):\n",
        "    # Split the duration into hours, minutes, and seconds\n",
        "    hours, minutes, seconds = map(int, duration.split(':'))\n",
        "\n",
        "    # Convert the duration to seconds\n",
        "    total_seconds = (hours * 3600) + (minutes * 60) + seconds\n",
        "    return total_seconds"
      ],
      "metadata": {
        "id": "xJTu0zL7-uD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio):\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=40).T, axis=0)\n",
        "    return mfccs\n",
        "\n",
        "def predict_emotion_for_time_frame(mp3_file_path, start_time, end_time):\n",
        "    # Load the long MP3 file\n",
        "    audio, sr = librosa.load(mp3_file_path, sr=22050)\n",
        "\n",
        "    # Calculate the start and end sample indices\n",
        "    start_sample = int(start_time * sr)\n",
        "    end_sample = int(end_time * sr)\n",
        "\n",
        "    # Extract the audio segment for the specified time frame\n",
        "    audio_segment = audio[start_sample:end_sample]\n",
        "\n",
        "    # Extract features from the audio segment\n",
        "    features = extract_features(audio_segment)\n",
        "    features = np.expand_dims(features, axis=0)\n",
        "    features = np.expand_dims(features, axis=2)\n",
        "\n",
        "    # Perform emotion prediction\n",
        "    predictions = model.predict(features)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    label_conversion = {'0': 'neutral','1': 'calm','2': 'happy','3': 'sad','4': 'angry','5': 'fearful','6': 'disgust','7': 'surprised'}\n",
        "    for key, value in label_conversion.items():\n",
        "      if int(key) == predicted_class:\n",
        "        predicted_emotion = value\n",
        "\n",
        "    return predicted_emotion\n"
      ],
      "metadata": {
        "id": "1LV8z4O9-xPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp3_file_path = '/content/Short Films/BGM/Aai Shapat.mp3' #changed the file path as per need"
      ],
      "metadata": {
        "id": "htsrjR-1HDTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emoBGM(df, mp3_file_path):\n",
        "  # Create a new column for predicted emotion\n",
        "  df['PredictedEmotionBGM'] = ''\n",
        "\n",
        "  # Iterate over each row in the DataFrame\n",
        "  for index, row in df.iterrows():\n",
        "      # Extract the start time and end time for the row\n",
        "      start_time = row['StartTime']\n",
        "      end_time = row['EndTime']\n",
        "\n",
        "      # Predict the emotion for the time frame\n",
        "      emotion = predict_emotion_for_time_frame(mp3_file_path, start_time, end_time)\n",
        "\n",
        "      # Store the predicted emotion in the 'PredictedEmotion' column\n",
        "      df.at[index, 'PredictedEmotionBGM'] = emotion\n"
      ],
      "metadata": {
        "id": "kgmte6kp-_1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model on the DataFrame"
      ],
      "metadata": {
        "id": "TrVW5qY4-5g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['StartTime'] = df['StartTime'].apply(duration_to_seconds)\n",
        "df['EndTime'] = df['EndTime'].apply(duration_to_seconds)\n"
      ],
      "metadata": {
        "id": "gmWWhldk-7o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = emoBGM(df)"
      ],
      "metadata": {
        "id": "SRODXYNV-8sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('InteriorCafeNight.csv', index=False)"
      ],
      "metadata": {
        "id": "Z50RKHWS_MkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBoOEIGj_Nmg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}